{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Example: if folder is named 'asvspoof2019-dataset'\nimport os\ndataset_path = '/kaggle/input/asvpoof-2019-dataset'\n\n# List files/folders inside this dataset\nprint(os.listdir(dataset_path))\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T12:45:55.688379Z","iopub.execute_input":"2025-07-23T12:45:55.688642Z","iopub.status.idle":"2025-07-23T12:45:55.708571Z","shell.execute_reply.started":"2025-07-23T12:45:55.688619Z","shell.execute_reply":"2025-07-23T12:45:55.707933Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"['asvspoof2019_Interspeech2019_submission.pdf', 'LICENSE_text.txt', 'README.txt', 'PA', 'asvspoof2019_evaluation_plan.pdf', 'LA']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/grip-unina/PoIForensics-Audio\n\n%cd PoIForensics-Audio\n%pip install -q -r requirements.txt       # python-3.10 on Kaggle works fine\n\n# Kaggle already ships with PyTorch + CUDA 12, so we relax the pinned\n# versions in requirements.txt and install everything else.\n!pip install --upgrade --quiet torch torchvision torchaudio \\\n    --index-url https://download.pytorch.org/whl/cu118         # PyTorch 2.2 at the time of writing\n\n# pydub needs ffmpeg to decode .wav / .flac\n!sudo apt-get update -y && sudo apt-get install -y ffmpeg\n\n# now the repo’s extras (torch is already satisfied)\n!pip install --quiet -r requirements.txt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T12:45:55.709572Z","iopub.execute_input":"2025-07-23T12:45:55.709821Z","iopub.status.idle":"2025-07-23T12:51:31.263379Z","shell.execute_reply.started":"2025-07-23T12:45:55.709802Z","shell.execute_reply":"2025-07-23T12:51:31.262651Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'PoIForensics-Audio'...\nremote: Enumerating objects: 36, done.\u001b[K\nremote: Counting objects: 100% (17/17), done.\u001b[K\nremote: Compressing objects: 100% (15/15), done.\u001b[K\nremote: Total 36 (delta 5), reused 7 (delta 2), pack-reused 19 (from 1)\u001b[K\nReceiving objects: 100% (36/36), 173.89 MiB | 41.75 MiB/s, done.\nResolving deltas: 100% (6/6), done.\nUpdating files: 100% (14/14), done.\n/kaggle/working/PoIForensics-Audio\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.5.2 requires torch>=2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.3/905.3 MB\u001b[0m \u001b[31m560.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1+cu118 which is incompatible.\u001b[0m\u001b[31m\nGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \nGet:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \nGet:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,851 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]      \nGet:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,765 kB]\nGet:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,268 kB]\nGet:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [75.9 kB]\nGet:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,470 kB]\nGet:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,138 kB] \nGet:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]\nGet:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,159 kB]\nHit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \nGet:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,976 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,163 kB]\nGet:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,573 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:25 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [51.0 kB]\nFetched 34.1 MB in 3s (12.9 MB/s)                            \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 82 not upgraded.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.5.2 requires torch>=2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os, pandas as pd\n\n# ── fixed folder pointers ────────────────────────────────────────────\nbase_dir  = '/kaggle/input/asvpoof-2019-dataset/LA/LA'\naudio_dir = f'{base_dir}/ASVspoof2019_LA_eval/flac'\nprotocol  = f'{base_dir}/ASVspoof2019_LA_cm_protocols/' \\\n            f'ASVspoof2019.LA.cm.eval.trl.txt'\n\nrows = []\nwith open(protocol) as fp:\n    for line in fp:\n        parts    = line.strip().split()\n        speaker  = parts[0]          # e.g. LA_0039\n        utt      = parts[1]          # e.g. LA_E_1000147  ✅ real file name\n        tag      = parts[-1]         # bonafide / spoof\n\n        rows.append([utt,\n                     f'{audio_dir}/{utt}.flac',\n                     speaker,\n                     'eval',\n                     0 if tag == 'bonafide' else 1,\n                     1, 1])\n\ncols = ['videoname','filepath','poi','context','label','in_tst','in_ref']\ndf   = pd.DataFrame(rows, columns=cols)\ndf.to_csv('../ASVspoof2019_eval.csv', index=False)\n\n# quick sanity-check\nmissing = df.loc[~df['filepath'].apply(os.path.exists)].shape[0]\nprint(f\"Wrote {len(df):,} rows → ../ASVspoof2019_eval.csv\")\nprint(\"Missing files:\", missing)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T12:51:31.264453Z","iopub.execute_input":"2025-07-23T12:51:31.264759Z","iopub.status.idle":"2025-07-23T12:56:18.132288Z","shell.execute_reply.started":"2025-07-23T12:51:31.264701Z","shell.execute_reply":"2025-07-23T12:56:18.131621Z"}},"outputs":[{"name":"stdout","text":"Wrote 71,237 rows → ../ASVspoof2019_eval.csv\nMissing files: 0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os, pandas as pd\n\n# ----------  where Kaggle mounted the three splits  -----------------\nBASE = '/kaggle/input/asvpoof-2019-dataset/LA/LA'\nSPLITS = {\n    'train': ('ASVspoof2019_LA_train', 'ASVspoof2019.LA.cm.train.trn.txt'),\n    'dev'  : ('ASVspoof2019_LA_dev',   'ASVspoof2019.LA.cm.dev.trl.txt'),\n    'eval' : ('ASVspoof2019_LA_eval',  'ASVspoof2019.LA.cm.eval.trl.txt'),\n}\n\nrows = []\nfor ctx, (folder, proto) in SPLITS.items():\n    audio_dir  = f'{BASE}/{folder}/flac'\n    proto_file = f'{BASE}/ASVspoof2019_LA_cm_protocols/{proto}'\n\n    with open(proto_file) as f:\n        for line in f:\n            _, utt, _, _, tag = line.strip().split()      # 2nd column = file-ID\n            rows.append([\n                utt,                                      # videoname\n                f'{audio_dir}/{utt}.flac',                # filepath\n                'asvspoof',                               # ← ONE global POI\n                ctx,                                      # context\n                0 if tag == 'bonafide' else 1,            # label\n                1 if ctx == 'eval' else 0,                # in_tst\n                1 if tag == 'bonafide' else 0,            # in_ref (bonafide)\n            ])\n\ncols = ['videoname','filepath','poi','context','label','in_tst','in_ref']\ndf   = pd.DataFrame(rows, columns=cols)\ndf.to_csv('../ASVspoof2019_global.csv', index=False)\n\nprint(df.context.value_counts())           # sanity-check\nprint(\"Missing files:\", (~df.filepath.apply(os.path.exists)).sum())\nprint(\"Reference rows all bonafide:\",\n      df.query('in_ref==1')['label'].unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T12:56:18.133888Z","iopub.execute_input":"2025-07-23T12:56:18.134134Z","iopub.status.idle":"2025-07-23T12:59:30.164231Z","shell.execute_reply.started":"2025-07-23T12:56:18.134113Z","shell.execute_reply":"2025-07-23T12:59:30.163625Z"}},"outputs":[{"name":"stdout","text":"context\neval     71237\ntrain    25380\ndev      24844\nName: count, dtype: int64\nMissing files: 0\nReference rows all bonafide: [0]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!python /kaggle/working/PoIForensics-Audio/extract_features.py \\\n    --dataset-csv /kaggle/working/ASVspoof2019_global.csv \\\n    --dataset-name ASVspoof2019_global \\\n    --weights /kaggle/working/PoIForensics-Audio/checkpoints/model_no_augmentation.th \\\n    --batch-size 64 --seconds 4 --gpu 0 --num-workers 4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T12:59:30.164911Z","iopub.execute_input":"2025-07-23T12:59:30.165085Z"}},"outputs":[{"name":"stdout","text":"Device is cuda:0\nDownloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|███████████████████████████████████████| 97.8M/97.8M [00:00<00:00, 275MB/s]\nCheckpoint Loaded!\nExtracting features:   5%|▋             | 5504/121461 [08:14<2:49:17, 11.42it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/*.csv\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" !python /kaggle/working/PoIForensics-Audio/compute_distances.py \\\n    --dataset-csv /kaggle/working/ASVspoof2019_global.csv \\\n    --dataset-name ASVspoof2019_global \\\n    --strategy ms","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load full score file\nscores_full = pd.read_csv('/kaggle/working/PoIForensics-Audio/scores/ASVspoof2019_global_ms.csv', index_col=0)\n\n# Load original manifest\nmanifest_full = pd.read_csv('/kaggle/working/ASVspoof2019_global.csv')\n\n# Merge to get labels back\nmerged_full = scores_full.reset_index().merge(manifest_full[['videoname', 'label']], on='videoname', how='left')\n\n# Set index back (optional)\nmerged_full = merged_full.set_index('videoname')\n\nprint(\"✅ Merged full scores shape:\", merged_full.shape)\nprint(\"Label distribution:\\n\", merged_full['label'].value_counts())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load full score file\nscores_full = pd.read_csv('/kaggle/working/PoIForensics-Audio/scores/ASVspoof2019_global_ms.csv', index_col=0)\n\n# Load manifest WITH context and check columns\nmanifest_full = pd.read_csv('/kaggle/working/ASVspoof2019_global.csv')\nprint(\"Manifest columns:\", manifest_full.columns.tolist())\n\n# Select correct columns\nmanifest_full = manifest_full[['videoname', 'label', 'context']]\n\n# Merge\nmerged_full = scores_full.reset_index().merge(manifest_full, on='videoname', how='left').set_index('videoname')\n\n# Check merged columns\nprint(\"Merged columns:\", merged_full.columns.tolist())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n# 1️⃣ Load scores\nscores_full = pd.read_csv('/kaggle/working/PoIForensics-Audio/scores/ASVspoof2019_global_ms.csv', index_col=0)\n\n# 2️⃣ Load manifest\nmanifest_full = pd.read_csv('/kaggle/working/ASVspoof2019_global.csv')[['videoname', 'label', 'context']]\n\n# 3️⃣ Merge\nmerged_full = scores_full.reset_index().merge(manifest_full, on='videoname', how='left').set_index('videoname')\n\nprint(\"✅ Merged columns:\", merged_full.columns.tolist())\n\n# 4️⃣ Use context_y for filtering (from manifest)\nmerged_eval = merged_full[merged_full['context_y'] == 'eval']\n\n# 1⃣  Make a *new* label array where “1” means BONAFIDE (real speech)\ny_true_bona = (merged_eval['label'] == 0).astype(int).values   # 1 = bonafide, 0 = spoof\n\n# 2⃣  The score stays “−distance” (higher ⇒ more bonafide)\ny_score = -merged_eval['value'].values\n\n# 3⃣  ROC, EER, AUC\nfpr, tpr, _ = roc_curve(y_true_bona, y_score)          # no pos_label needed\neer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\nauc = roc_auc_score(y_true_bona, y_score)\n\nprint(f\"✅ EER  = {eer*100:.4f}%\")\nprint(f\"✅ AUC  = {auc*100:.4f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------- PATCH compute_distances.py  ---------------------------------\nimport pathlib, re, shutil\n\nSRC = pathlib.Path('/kaggle/working/PoIForensics-Audio/compute_distances.py')\nDST = SRC.parent / 'compute_distances_check.py'\n\n# 1️⃣ copy the original script\nshutil.copyfile(SRC, DST)\n\n# 2️⃣ read & patch two lines:\n#   a) drop the (df['context'] != context) filter\n#   b) allow references from *all* contexts when concatenating\nwith open(DST, 'r') as f:\n    code = f.read()\n\ncode = re.sub(r\"\\(df\\['in_ref'\\]\\s*==\\s*1\\)\\s*&\\s*\\(df\\['context'\\]\\s*!=\\s*con-\n\ncode = code.replace(\n    \"[k for k in list_dict if k != context]\",\n    \"[k for k in list_dict]\"  # keep every context\n)\n\nwith open(DST, 'w') as f:\n    f.write(code)\n\nprint(\"✅ Patched script written to:\", DST)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python /kaggle/working/PoIForensics-Audio/compute_distances_check.py \\\n    --dataset-csv /kaggle/working/ASVspoof2019_global.csv \\\n    --dataset-name ASVspoof2019_global \\\n    --strategy ms\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd, numpy as np\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n# 1⃣  Load data\nscores_full = pd.read_csv(\n    '/kaggle/working/PoIForensics-Audio/scores/ASVspoof2019_global_ms.csv',\n    index_col=0\n)\nmanifest = pd.read_csv(\n    '/kaggle/working/ASVspoof2019_global.csv',\n    usecols=['videoname', 'label', 'context']\n)\n\n# 2⃣  Merge and keep context_y\nmerged = (\n    scores_full.reset_index()\n    .merge(manifest, on='videoname', how='left')        # adds context\n    .set_index('videoname')\n)\n\n# 3⃣  Filter eval rows via context_y\neval_set = merged[merged['context_y'] == 'eval']\n\n# 4⃣  Prepare labels (1 = bonafide) and scores (larger = more bonafide)\ny_true  = (eval_set['label'] == 0).astype(int).values\ny_score = -eval_set['value'].values\n\n# 5⃣  Compute EER & AUC\nfpr, tpr, _ = roc_curve(y_true, y_score)\neer = fpr[np.argmin(np.abs(fpr - (1 - tpr)))]\nauc = roc_auc_score(y_true, y_score)\n\nprint(f\"✅ NEW EER  = {eer*100:.4f}%\")\nprint(f\"✅ NEW AUC  = {auc*100:.4f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# HuBERT ","metadata":{}},{"cell_type":"code","source":"# Install torchaudio (Kaggle already has torch 2.x CUDA 12)\n!pip install --quiet torchaudio==2.1.2\n\nimport torch, torchaudio, os, glob, tqdm, numpy as np, pandas as pd\ndevice = torch.device(\"cuda:0\")\n\n# Load Facebook HuBERT Base (pre-trained on LibriSpeech 960 h)\nbundle = torchaudio.pipelines.HUBERT_BASE\nhubert = bundle.get_model().to(device).eval()\nprint(\"HuBERT ⇒\", bundle._params)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Extracting file-level HuBERT embeddings","metadata":{}},{"cell_type":"code","source":"CSV = '/kaggle/working/ASVspoof2019_global.csv'\nOUT_DIR = '/kaggle/working/hubert_feats'\nos.makedirs(OUT_DIR, exist_ok=True)\n\ndf = pd.read_csv(CSV)\nwav_list = df['filepath'].tolist()\n\ndef embed_one(path):\n    wav, sr = torchaudio.load(path)\n    if sr != bundle.sample_rate:\n        wav = torchaudio.functional.resample(wav, sr, bundle.sample_rate)\n    with torch.no_grad():\n        w = wav.to(device)\n        feat, _ = hubert.extract_features(w)   # list of layer outputs\n        x = feat[-1].squeeze(0).mean(0).cpu().numpy()  # (768,)\n    np.save(os.path.join(OUT_DIR, os.path.basename(path)+'.npy'), x)\n\nfor p in tqdm.tqdm(wav_list, desc=\"HuBERT embedding\"):\n    out_f = os.path.join(OUT_DIR, os.path.basename(p)+'.npy')\n    if os.path.isfile(out_f):        # resume capability\n        continue\n    embed_one(p)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Building train / dev (fit) and eval (test) matrices","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n# Helper to load *.npy → list of vectors\ndef load_split(ctx):\n    subset = df[df.context == ctx]\n    X = np.stack([np.load(f\"{OUT_DIR}/{os.path.basename(p)}.npy\")\n                  for p in subset['filepath']])\n    y = subset['label'].values          # 0 = bonafide, 1 = spoof\n    return X, y\n\nX_train, y_train = load_split('train')\nX_dev,   y_dev   = load_split('dev')\nX_eval,  y_eval  = load_split('eval')\n\nX_fit   = np.concatenate([X_train, X_dev], 0)\ny_fit   = np.concatenate([y_train, y_dev], 0)\n\n# Shuffle & standardize\nX_fit, y_fit = shuffle(X_fit, y_fit, random_state=42)\nscaler = StandardScaler().fit(X_fit)\nX_fit  = scaler.transform(X_fit)\nX_eval = scaler.transform(X_eval)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train an RBF - kernel SVM","metadata":{}},{"cell_type":"code","source":"import time\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nstart = time.time()\n\nsvm = SVC(\n    C=10,\n    gamma='scale',\n    probability=True,\n    class_weight='balanced',\n    verbose=True        # ← prints iteration progress\n)\nsvm.fit(X_fit, y_fit)\n\nprint(f\"\\n✅ Training finished in {(time.time() - start)/60:.1f} minutes\")\n\n# ---------- Evaluation ----------\nbonafide_prob = svm.predict_proba(X_eval)[:, 0]   # class “0” = bonafide\ny_true  = (y_eval == 0).astype(int)               # 1 = bonafide\ny_score = bonafide_prob\n\nfpr, tpr, _ = roc_curve(y_true, y_score)\neer = fpr[np.argmin(abs(fpr - (1 - tpr)))]\nauc = roc_auc_score(y_true, y_score)\n\nprint(f\"EER  = {eer*100:.3f}%\")\nprint(f\"AUC  = {auc*100:.3f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LightGBM","metadata":{}},{"cell_type":"code","source":"!pip install --quiet lightgbm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Loading HuBERT embeddings","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\n# Paths\nCSV = '/kaggle/working/ASVspoof2019_global.csv'\nFEAT_DIR = '/kaggle/working/hubert_feats'   # where your .npy files are stored\n\n# Load manifest\ndf = pd.read_csv(CSV)\n\n# Helper to load embeddings\ndef load_features(context):\n    subset = df[df['context'] == context]\n    X = np.stack([\n        np.load(os.path.join(FEAT_DIR, os.path.basename(p) + '.npy'))\n        for p in subset['filepath']\n    ])\n    y = subset['label'].values  # 0 = bonafide, 1 = spoof\n    return X, y\n\n# Train/dev for fitting; eval for testing\nX_train, y_train = load_features('train')\nX_dev, y_dev = load_features('dev')\nX_eval, y_eval = load_features('eval')\n\n# Combine train+dev\nimport numpy as np\nX_fit = np.vstack([X_train, X_dev])\ny_fit = np.concatenate([y_train, y_dev])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n# Shuffle and scale\nX_fit, y_fit = shuffle(X_fit, y_fit, random_state=42)\nscaler = StandardScaler().fit(X_fit)\nX_fit_scaled = scaler.transform(X_fit)\nX_eval_scaled = scaler.transform(X_eval)\n\n# LightGBM dataset\ntrain_data = lgb.Dataset(X_fit_scaled, label=y_fit)\n\n# Train params\nparams = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'is_unbalance': True,\n    'learning_rate': 0.05,\n    'num_leaves': 31,\n    'max_depth': -1,\n    'verbosity': -1,\n    'boosting_type': 'gbdt'\n}\n\n# Train model\nbst = lgb.train(params, train_data, num_boost_round=100)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict: higher score = more likely spoof\ny_prob = bst.predict(X_eval_scaled)\ny_true = (y_eval == 0).astype(int)    # 1 = bonafide\n\n# Invert scores so higher = bonafide\ny_score = 1 - y_prob\n\n# Compute EER & AUC\nfpr, tpr, _ = roc_curve(y_true, y_score)\neer = fpr[np.argmin(np.abs(fpr - (1 - tpr)))]\nauc = roc_auc_score(y_true, y_score)\n\nprint(f\"✅ LightGBM + HuBERT → EER = {eer*100:.3f}%, AUC = {auc*100:.3f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm /kaggle/working/working_directory.zip > /dev/null 2>&1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:52:41.176896Z","iopub.execute_input":"2025-07-23T18:52:41.177515Z","iopub.status.idle":"2025-07-23T18:52:41.629957Z","shell.execute_reply.started":"2025-07-23T18:52:41.177480Z","shell.execute_reply":"2025-07-23T18:52:41.628815Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"!zip -rq /kaggle/working/working_directory.zip /kaggle/working/*\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T18:53:01.649862Z","iopub.execute_input":"2025-07-23T18:53:01.650695Z","iopub.status.idle":"2025-07-23T18:53:48.079642Z","shell.execute_reply.started":"2025-07-23T18:53:01.650664Z","shell.execute_reply":"2025-07-23T18:53:48.078809Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}